{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import ale_py\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack, VecTransposeImage\n",
    "from stable_baselines3.common.atari_wrappers import MaxAndSkipEnv\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "from gymnasium.wrappers import MaxAndSkipObservation, ResizeObservation, GrayscaleObservation, FrameStackObservation, ReshapeObservation\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "gym.register_envs(ale_py)\n",
    "from datetime import datetime\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.ppo.policies import MlpPolicy\n",
    "from wandb.integration.sb3 import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV_NAME = 'ALE/MarioBros-v5'\n",
    "\n",
    "# configuration file\n",
    "config = {\n",
    "    \"policy_type\": \"CnnPolicy\",\n",
    "    \"total_timesteps\": 1000000,\n",
    "    \"env_name\": \"ALE/Breakout-v5\", # ALE/MarioBros-v5\n",
    "    \"model_name\": \"A2C_MarioBros\",\n",
    "    \"export_path\": \"./exports/\",\n",
    "    \"videos_path\": \"./videos/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super().__init__(env)\n",
    "        # Check that 'FIRE' is a valid action in the environment\n",
    "        assert 'FIRE' in env.unwrapped.get_action_meanings(), \"Environment does not support 'FIRE' action\"\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3, \"Action space too small for expected actions\"\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        # Reset the environment\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "\n",
    "        # Perform the FIRE action\n",
    "        obs, _, terminated, truncated, _ = self.env.step(1)\n",
    "        if terminated or truncated:  # If game ends after FIRE, reset again\n",
    "            obs, info = self.env.reset(**kwargs)\n",
    "\n",
    "        return obs, info\n",
    "\n",
    "\n",
    "def make_env(env_name, render_mode=None):\n",
    "    def _init():\n",
    "        env = gym.make(env_name, render_mode=render_mode)\n",
    "        print(\"Standard Env.        : {}\".format(env.observation_space.shape))\n",
    "        env = FireResetEnv(env)\n",
    "        print(\"FireResetEnv          : {}\".format(env.observation_space.shape))\n",
    "        env = ResizeObservation(env, (84, 84))\n",
    "        print(\"ResizeObservation    : {}\".format(env.observation_space.shape))\n",
    "        env = GrayscaleObservation(env, keep_dim=True)\n",
    "        print(\"GrayscaleObservation : {}\".format(env.observation_space.shape))\n",
    "        env = ScaledFloatFrame(env)\n",
    "        print(\"ScaledFloatFrame     : {}\".format(env.observation_space.shape))\n",
    "        env = Monitor(env, allow_early_resets=True) # from stable baselines\n",
    "        print(\"Monitor               : {}\".format(env.observation_space.shape))\n",
    "\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "\n",
    "# env = DummyVecEnv([make_env(config[\"env_name\"])])\n",
    "# # stack 4 frames\n",
    "# env = VecFrameStack(env, n_stack=4)\n",
    "# print(\"Post VecFrameStack Shape: {}\".format(env.observation_space.shape))\n",
    "\n",
    "# # convert back to PyTorch format (channel-first)\n",
    "# env = VecTransposeImage(env)\n",
    "# print(\"Final Observation Space: {}\".format(env.observation_space.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Env.        : (210, 160, 3)\n",
      "FireResetEnv          : (210, 160, 3)\n",
      "ResizeObservation    : (84, 84, 3)\n",
      "GrayscaleObservation : (84, 84, 1)\n",
      "ScaledFloatFrame     : (84, 84, 1)\n",
      "Monitor               : (84, 84, 1)\n",
      "Post VecFrameStack Shape: (84, 84, 4)\n",
      "Final Observation Space: (4, 84, 84)\n",
      "Render mode after wrapping: rgb_array\n"
     ]
    }
   ],
   "source": [
    "env = DummyVecEnv([make_env(config[\"env_name\"], render_mode=\"rgb_array\")])\n",
    "# stack 4 frames\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "print(\"Post VecFrameStack Shape: {}\".format(env.observation_space.shape))\n",
    "\n",
    "# convert back to PyTorch format (channel-first)\n",
    "env = VecTransposeImage(env)\n",
    "print(\"Final Observation Space: {}\".format(env.observation_space.shape))\n",
    "\n",
    "print(\"Render mode after wrapping:\", env.render_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = A2C.load(\"Breakout-v5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards: [array([3.], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "from PIL import Image\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "\n",
    "rewards_glb = []\n",
    "num_episodes = 2\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    frames = []\n",
    "    rewards_episode = []\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        # done = terminated or truncated\n",
    "        rewards_episode.append(reward)\n",
    "\n",
    "        frames.append(env.render())\n",
    "\n",
    "    rewards_glb.append(sum(rewards_episode))\n",
    "    # e.g. fps=50 == duration=20 (1000 * 1/50)\n",
    "    imageio.mimwrite(\"model_name\" +'_'+ str(i) +'.gif', frames, duration=20)\n",
    "\n",
    "print(\"Rewards:\", rewards_glb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make code for elimating ok.txt\n",
    "# os.remove(\"ok.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_prova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
