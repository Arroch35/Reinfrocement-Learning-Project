{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stable_baselines3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01male_py\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DQN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvec_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DummyVecEnv, VecFrameStack, VecTransposeImage\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01matari_wrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaxAndSkipEnv\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'stable_baselines3'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import ale_py\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack, VecTransposeImage\n",
    "from stable_baselines3.common.atari_wrappers import MaxAndSkipEnv\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "from gymnasium.wrappers import MaxAndSkipObservation, ResizeObservation, GrayscaleObservation, FrameStackObservation, ReshapeObservation\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "gym.register_envs(ale_py)\n",
    "from datetime import datetime\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.ppo.policies import MlpPolicy\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "import collections\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecEnvWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV_NAME = 'ALE/MarioBros-v5'\n",
    "\n",
    "# configuration file\n",
    "config = {\n",
    "    \"policy_type\": \"CnnPolicy\",\n",
    "    \"total_timesteps\": 1000000,\n",
    "    \"env_name\": \"ALE/DonkeyKong-v5\", \n",
    "    \"model_name\": \"ALE/DonkeyKong-v5\",\n",
    "    \"export_path\": \"./exports/\",\n",
    "    \"videos_path\": \"./videos/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVecTransposeImage(VecEnvWrapper):\n",
    "    def __init__(self, venv, skip=False):\n",
    "        super().__init__(venv)\n",
    "        self.skip = skip\n",
    "\n",
    "        # Get original shape: e.g., (84, 84, 4)\n",
    "        old_shape = self.observation_space.shape\n",
    "        # Transpose shape to (C, H, W)\n",
    "        new_shape = (old_shape[2], old_shape[0], old_shape[1])  # (4, 84, 84)\n",
    "\n",
    "        # Use the original low/high if they are uniform; if not, use min/max appropriately\n",
    "        low_val = self.observation_space.low.min()\n",
    "        high_val = self.observation_space.high.max()\n",
    "\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=low_val,\n",
    "            high=high_val,\n",
    "            shape=new_shape,\n",
    "            dtype=self.observation_space.dtype\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.venv.reset()\n",
    "        return self.transpose_observations(obs)\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        self.venv.step_async(actions)\n",
    "\n",
    "    def step_wait(self):\n",
    "        obs, rewards, dones, infos = self.venv.step_wait()\n",
    "        return self.transpose_observations(obs), rewards, dones, infos\n",
    "\n",
    "    def transpose_observations(self, obs):\n",
    "        if self.skip:\n",
    "            return obs\n",
    "        if isinstance(obs, dict):\n",
    "            for key, val in obs.items():\n",
    "                obs[key] = self._transpose(val)\n",
    "            return obs\n",
    "        else:\n",
    "            return self._transpose(obs)\n",
    "\n",
    "    def _transpose(self, obs):\n",
    "        # obs shape is (n_envs, H, W, C) -> transpose to (n_envs, C, H, W)\n",
    "        return obs.transpose(0, 3, 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        # The original shape remains (84,84,1), but the dtype and range change\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0.0,\n",
    "            high=1.0,\n",
    "            shape=self.observation_space.shape,\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "\n",
    "# class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "#     def observation(self, obs):\n",
    "#         return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "\n",
    "\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super().__init__(env)\n",
    "        # Check that 'FIRE' is a valid action in the environment\n",
    "        assert 'FIRE' in env.unwrapped.get_action_meanings(), \"Environment does not support 'FIRE' action\"\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3, \"Action space too small for expected actions\"\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        # Reset the environment\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "\n",
    "        # Perform the FIRE action\n",
    "        obs, _, terminated, truncated, _ = self.env.step(1)\n",
    "        if terminated or truncated:  # If game ends after FIRE, reset again\n",
    "            obs, info = self.env.reset(**kwargs)\n",
    "\n",
    "        return obs, info\n",
    "        \n",
    "# Custom wrapper to add channel dimension\n",
    "class AddChannelDimension(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape\n",
    "        # Update the observation space to include a channel dimension\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(obs_shape[0], obs_shape[1], 1),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # Add a channel dimension\n",
    "        return np.expand_dims(observation, axis=-1)\n",
    "\n",
    "# class MaxAndSkipEnv(gym.Wrapper):\n",
    "#     def __init__(self, env=None, skip=4):\n",
    "#         super(MaxAndSkipEnv, self).__init__(env)\n",
    "#         self._obs_buffer = collections.deque(maxlen=2)\n",
    "#         self._skip = skip\n",
    "\n",
    "#     def step(self, action):\n",
    "#         total_reward = 0.0\n",
    "#         done = None\n",
    "#         for _ in range(self._skip):\n",
    "#             obs, reward, terminated,truncated, info = self.env.step(action)\n",
    "#             done = terminated or truncated\n",
    "#             self._obs_buffer.append(obs)\n",
    "#             total_reward += reward\n",
    "#             if done:\n",
    "#                 break\n",
    "#         max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
    "#         return max_frame, total_reward, terminated, truncated, info\n",
    "\n",
    "    # def reset(self, *, seed=None, options=None):\n",
    "    #     self._obs_buffer.clear()\n",
    "    #     obs, info = self.env.reset(seed=seed, options=options)\n",
    "    #     self._obs_buffer.append(obs)\n",
    "    #     return obs, info\n",
    "\n",
    "\n",
    "def make_env(env_name, obs_type=\"grayscale\", render_mode=None,):\n",
    "    def _init():\n",
    "        env = gym.make(env_name, obs_type=\"grayscale\", render_mode=render_mode)\n",
    "        print(\"Standard Env.        : {}\".format(env.observation_space.shape))\n",
    "        env = FireResetEnv(env)\n",
    "        print(\"FireResetEnv          : {}\".format(env.observation_space.shape))\n",
    "        # env = MaxAndSkipEnv(env)\n",
    "        # print(\"MaxAndSkipEnv        : {}\".format(env.observation_space.shape))\n",
    "        env = ResizeObservation(env, (84, 84))\n",
    "        print(\"ResizeObservation    : {}\".format(env.observation_space.shape))\n",
    "        env = AddChannelDimension(env)  # Add channel dimension here\n",
    "        print(\"AddChannelDimension  : {}\".format(env.observation_space.shape))\n",
    "        # env = GrayscaleObservation(env, keep_dim=True)\n",
    "        # print(\"GrayscaleObservation : {}\".format(env.observation_space.shape))\n",
    "        \n",
    "        env = ScaledFloatFrame(env)\n",
    "        print(\"ScaledFloatFrame     : {}\".format(env.observation_space.shape))\n",
    "        \n",
    "        # env = Monitor(env, allow_early_resets=False) # from stable baselines\n",
    "        # print(\"Monitor               : {}\".format(env.observation_space.shape))\n",
    "\n",
    "        return env\n",
    "    return _init\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Env.        : (210, 160)\n",
      "FireResetEnv          : (210, 160)\n",
      "ResizeObservation    : (84, 84)\n",
      "AddChannelDimension  : (84, 84, 1)\n",
      "ScaledFloatFrame     : (84, 84, 1)\n",
      "Post VecFrameStack Shape: (84, 84, 4)\n",
      "Final Observation Space: (4, 84, 84)\n",
      "Render mode after wrapping: rgb_array\n"
     ]
    }
   ],
   "source": [
    "# env = DummyVecEnv([make_env(config[\"env_name\"], render_mode=\"rgb_array\")])\n",
    "env = make_vec_env(env_id=make_env(config[\"env_name\"], render_mode=\"rgb_array\"), n_envs=1)\n",
    "# stack 4 frames\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "print(\"Post VecFrameStack Shape: {}\".format(env.observation_space.shape))\n",
    "\n",
    "# convert back to PyTorch format (channel-first)\n",
    "env = MyVecTransposeImage(env)\n",
    "print(\"Final Observation Space: {}\".format(env.observation_space.shape))\n",
    "\n",
    "print(\"Render mode after wrapping:\", env.render_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = A2C.load(\"../models/best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards: [array([200.], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "from PIL import Image\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "\n",
    "rewards_glb = []\n",
    "num_episodes = 2\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    frames = []\n",
    "    rewards_episode = []\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        # done = terminated or truncated\n",
    "        rewards_episode.append(reward)\n",
    "\n",
    "        frames.append(env.render())\n",
    "\n",
    "    rewards_glb.append(sum(rewards_episode))\n",
    "    # e.g. fps=50 == duration=20 (1000 * 1/50)\n",
    "    imageio.mimwrite(\"model_name\" +'_'+ str(i) +'.gif', frames, duration=20)\n",
    "\n",
    "print(\"Rewards:\", rewards_glb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make code for elimating ok.txt\n",
    "# os.remove(\"ok.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
