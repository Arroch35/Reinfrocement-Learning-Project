{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "import stable_baselines3 as sb3\n",
    "from stable_baselines3 import PPO\n",
    "from gymnasium.wrappers import ResizeObservation\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "from PIL import Image\n",
    "from stable_baselines3.common.vec_env import VecEnvWrapper\n",
    "import ale_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_right=\"../../models/pong/left_best_model.zip\"\n",
    "model_path_left=\"../../models/pong/right_best_model.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is for testing right side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledFloatFrame     : (84, 84, 1)\n",
      "DummyVecEnv          : (84, 84, 1)\n",
      "VecFrameStack         : (84, 84, 4)\n",
      "MyVecTransposeImage  : (4, 84, 84)\n",
      "Gameplay saved as videos/right_paddle_gameplay.gif\n",
      "Total Reward: 14.0\n"
     ]
    }
   ],
   "source": [
    "# This code is for testing right side\n",
    "\n",
    "class MyVecTransposeImage(VecEnvWrapper):\n",
    "    def __init__(self, venv, skip=False):\n",
    "        super().__init__(venv)\n",
    "        self.skip = skip\n",
    "\n",
    "        # Get original shape: e.g., (84, 84, 4)\n",
    "        old_shape = self.observation_space.shape\n",
    "        # Transpose shape to (C, H, W)\n",
    "        new_shape = (old_shape[2], old_shape[0], old_shape[1])  # (4, 84, 84)\n",
    "\n",
    "        # Use the original low/high if they are uniform; if not, use min/max appropriately\n",
    "        low_val = self.observation_space.low.min()\n",
    "        high_val = self.observation_space.high.max()\n",
    "\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=low_val,\n",
    "            high=high_val,\n",
    "            shape=new_shape,\n",
    "            dtype=self.observation_space.dtype\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.venv.reset()\n",
    "        return self.transpose_observations(obs)\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        self.venv.step_async(actions)\n",
    "\n",
    "    def step_wait(self):\n",
    "        obs, rewards, dones, infos = self.venv.step_wait()\n",
    "        return self.transpose_observations(obs), rewards, dones, infos\n",
    "\n",
    "    def transpose_observations(self, obs):\n",
    "        if self.skip:\n",
    "            return obs\n",
    "        if isinstance(obs, dict):\n",
    "            for key, val in obs.items():\n",
    "                obs[key] = self._transpose(val)\n",
    "            return obs\n",
    "        else:\n",
    "            return self._transpose(obs)\n",
    "\n",
    "    def _transpose(self, obs):\n",
    "        # obs shape is (n_envs, H, W, C) -> transpose to (n_envs, C, H, W)\n",
    "        return obs.transpose(0, 3, 1, 2)\n",
    "    \n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0.0,\n",
    "            high=1.0,\n",
    "            shape=self.observation_space.shape,\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "\n",
    "class AddChannelDimension(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(obs_shape[0], obs_shape[1], 1),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # Add a channel dimension\n",
    "        return np.expand_dims(observation, axis=-1)\n",
    "\n",
    "\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super().__init__(env)\n",
    "        assert 'FIRE' in env.unwrapped.get_action_meanings(), \"Environment does not support 'FIRE' action\"\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3, \"Action space too small for expected actions\"\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        obs, _, terminated, truncated, _ = self.env.step(1)\n",
    "        if terminated or truncated:\n",
    "            obs, info = self.env.reset(**kwargs)\n",
    "        return obs, info\n",
    "\n",
    "\n",
    "# Custom wrapper to transpose frames to channel-first\n",
    "class ChannelFirstWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=self.observation_space.low.transpose(2, 0, 1),\n",
    "            high=self.observation_space.high.transpose(2, 0, 1),\n",
    "            shape=(obs_shape[2], obs_shape[0], obs_shape[1]),\n",
    "            dtype=self.observation_space.dtype,\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return obs.transpose(2, 0, 1)  # Convert to (C, H, W)\n",
    "\n",
    "\n",
    "# Function to create the test environment with preprocessing\n",
    "def create_test_env(env_name, n_stack=4):\n",
    "    def _init():\n",
    "        env = gym.make(env_name, obs_type=\"grayscale\", render_mode=\"rgb_array\")\n",
    "        env = FireResetEnv(env)\n",
    "        env = ResizeObservation(env, (84, 84))\n",
    "        env = AddChannelDimension(env)\n",
    "        env = ScaledFloatFrame(env)\n",
    "        print(\"ScaledFloatFrame     : {}\".format(env.observation_space.shape))\n",
    "        return env\n",
    "\n",
    "    env = DummyVecEnv([_init])  # Create vectorized environment\n",
    "    print(\"DummyVecEnv          : {}\".format(env.observation_space.shape))\n",
    "    env = VecFrameStack(env, n_stack=n_stack)  # Stack 4 frames\n",
    "    print(\"VecFrameStack         : {}\".format(env.observation_space.shape))\n",
    "    env = MyVecTransposeImage(env)\n",
    "    print(\"MyVecTransposeImage  : {}\".format(env.observation_space.shape))\n",
    "    return env\n",
    "\n",
    "\n",
    "# Function to save gameplay as a GIF\n",
    "def save_video_as_gif(frames, filename=\"gameplay.gif\"):\n",
    "    frames = [Image.fromarray(frame) for frame in frames]\n",
    "    frames[0].save(\n",
    "        filename,\n",
    "        save_all=True,\n",
    "        append_images=frames[1:],\n",
    "        duration=20,  # Set the frame duration (in ms)\n",
    "        loop=0  # Infinite loop\n",
    "    )\n",
    "    print(f\"Gameplay saved as {filename}\")\n",
    "\n",
    "\n",
    "# Test the trained model and record video\n",
    "def test_model_and_save_video(model_path, env_name, timesteps=2500, gif_filename=\"gameplay.gif\"):\n",
    "    # Load the trained model\n",
    "    model = PPO.load(model_path)\n",
    "\n",
    "    # Create the test environment\n",
    "    env = create_test_env(env_name)\n",
    "    obs = env.reset()\n",
    "\n",
    "    frames = []\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in range(timesteps):\n",
    "        # Get action from the model\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, dones, infos = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        # Render and store the frame\n",
    "        rendered_frame = env.envs[0].render()\n",
    "        frames.append(rendered_frame)\n",
    "\n",
    "        if dones.any():  # If any environment finishes\n",
    "            print(f\"Episode finished after {t + 1} timesteps.\")\n",
    "            break\n",
    "\n",
    "    # Save the video as a GIF\n",
    "    save_video_as_gif(frames, filename=gif_filename)\n",
    "\n",
    "    print(f\"Total Reward: {total_reward.sum()}\")\n",
    "    env.close()\n",
    "\n",
    "\n",
    "# Test the right-paddle model and save video as a GIF\n",
    "test_model_and_save_video(\n",
    "    model_path=model_path_right,\n",
    "    env_name=\"PongNoFrameskip-v4\",\n",
    "    timesteps=4500,\n",
    "    gif_filename=\"../../videos/pong/right_paddle_gameplay.gif\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is for testing left side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledFloatFrame     : (84, 84, 1)\n",
      "InvertPongWrapper    : (84, 84, 1)\n",
      "DummyVecEnv          : (84, 84, 1)\n",
      "VecFrameStack         : (84, 84, 4)\n",
      "MyVecTransposeImage  : (4, 84, 84)\n",
      "Gameplay saved as videos/left_paddle_gameplay_as_left_agent.gif\n",
      "Total Reward: 7.0\n"
     ]
    }
   ],
   "source": [
    "# This code is for testing left side\n",
    "\n",
    "class InvertPongWrapper(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Wrapper to invert the observations and actions to train the left paddle in Pong.\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "        # Directly copy the low and high values from the original observation space\n",
    "        obs_space = self.observation_space\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=obs_space.low,  # No need to flip as values are uniform\n",
    "            high=obs_space.high,\n",
    "            shape=obs_space.shape,\n",
    "            dtype=obs_space.dtype,\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        \"\"\"\n",
    "        Flip the screen horizontally so that the left paddle is treated as the primary agent.\n",
    "        \"\"\"\n",
    "        return np.flip(obs, axis=1)  # Flip the width axis\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Flip the actions to control the left paddle.\n",
    "        \"\"\"\n",
    "        # Invert the action logic\n",
    "        if action == 2:  # RIGHT\n",
    "            action = 3  # LEFT\n",
    "        elif action == 3:  # LEFT\n",
    "            action = 2  # RIGHT\n",
    "        elif action == 4:  # RIGHTFIRE\n",
    "            action = 5  # LEFTFIRE\n",
    "        elif action == 5:  # LEFTFIRE\n",
    "            action = 4  # RIGHTFIRE\n",
    "\n",
    "        # Perform the step with the flipped action\n",
    "        return super().step(action)\n",
    "\n",
    "class MyVecTransposeImage(VecEnvWrapper):\n",
    "    def __init__(self, venv, skip=False):\n",
    "        super().__init__(venv)\n",
    "        self.skip = skip\n",
    "\n",
    "        # Get original shape: e.g., (84, 84, 4)\n",
    "        old_shape = self.observation_space.shape\n",
    "        # Transpose shape to (C, H, W)\n",
    "        new_shape = (old_shape[2], old_shape[0], old_shape[1])  # (4, 84, 84)\n",
    "\n",
    "        # Use the original low/high if they are uniform; if not, use min/max appropriately\n",
    "        low_val = self.observation_space.low.min()\n",
    "        high_val = self.observation_space.high.max()\n",
    "\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=low_val,\n",
    "            high=high_val,\n",
    "            shape=new_shape,\n",
    "            dtype=self.observation_space.dtype\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.venv.reset()\n",
    "        return self.transpose_observations(obs)\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        self.venv.step_async(actions)\n",
    "\n",
    "    def step_wait(self):\n",
    "        obs, rewards, dones, infos = self.venv.step_wait()\n",
    "        return self.transpose_observations(obs), rewards, dones, infos\n",
    "\n",
    "    def transpose_observations(self, obs):\n",
    "        if self.skip:\n",
    "            return obs\n",
    "        if isinstance(obs, dict):\n",
    "            for key, val in obs.items():\n",
    "                obs[key] = self._transpose(val)\n",
    "            return obs\n",
    "        else:\n",
    "            return self._transpose(obs)\n",
    "\n",
    "    def _transpose(self, obs):\n",
    "        # obs shape is (n_envs, H, W, C) -> transpose to (n_envs, C, H, W)\n",
    "        return obs.transpose(0, 3, 1, 2)\n",
    "    \n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0.0,\n",
    "            high=1.0,\n",
    "            shape=self.observation_space.shape,\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "\n",
    "class AddChannelDimension(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(obs_shape[0], obs_shape[1], 1),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # Add a channel dimension\n",
    "        return np.expand_dims(observation, axis=-1)\n",
    "\n",
    "\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super().__init__(env)\n",
    "        assert 'FIRE' in env.unwrapped.get_action_meanings(), \"Environment does not support 'FIRE' action\"\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3, \"Action space too small for expected actions\"\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        obs, _, terminated, truncated, _ = self.env.step(1)\n",
    "        if terminated or truncated:\n",
    "            obs, info = self.env.reset(**kwargs)\n",
    "        return obs, info\n",
    "\n",
    "\n",
    "# Custom wrapper to transpose frames to channel-first\n",
    "class ChannelFirstWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=self.observation_space.low.transpose(2, 0, 1),\n",
    "            high=self.observation_space.high.transpose(2, 0, 1),\n",
    "            shape=(obs_shape[2], obs_shape[0], obs_shape[1]),\n",
    "            dtype=self.observation_space.dtype,\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return obs.transpose(2, 0, 1)  # Convert to (C, H, W)\n",
    "\n",
    "\n",
    "# Function to create the test environment with preprocessing\n",
    "def create_test_env(env_name, n_stack=4):\n",
    "    def _init():\n",
    "        env = gym.make(env_name, obs_type=\"grayscale\", render_mode=\"rgb_array\")\n",
    "        env = FireResetEnv(env)\n",
    "        env = ResizeObservation(env, (84, 84))\n",
    "        env = AddChannelDimension(env)\n",
    "        env = ScaledFloatFrame(env)\n",
    "        print(\"ScaledFloatFrame     : {}\".format(env.observation_space.shape))\n",
    "        env = InvertPongWrapper(env)\n",
    "        print(\"InvertPongWrapper    : {}\".format(env.observation_space.shape))\n",
    "        return env\n",
    "\n",
    "    env = DummyVecEnv([_init])  # Create vectorized environment\n",
    "    print(\"DummyVecEnv          : {}\".format(env.observation_space.shape))\n",
    "    env = VecFrameStack(env, n_stack=n_stack)  # Stack 4 frames\n",
    "    print(\"VecFrameStack         : {}\".format(env.observation_space.shape))\n",
    "    env = MyVecTransposeImage(env)\n",
    "    print(\"MyVecTransposeImage  : {}\".format(env.observation_space.shape))\n",
    "    return env\n",
    "\n",
    "\n",
    "# Function to save gameplay as a GIF from the perspective of the left agent\n",
    "def save_video_as_left_agent(frames, filename=\"gameplay_as_left_agent.gif\"):\n",
    "    flipped_frames = [np.flip(frame, axis=1) for frame in frames]  # Flip frames horizontally\n",
    "    pil_frames = [Image.fromarray(frame) for frame in flipped_frames]\n",
    "    pil_frames[0].save(\n",
    "        filename,\n",
    "        save_all=True,\n",
    "        append_images=pil_frames[1:],\n",
    "        duration=20,  # Set the frame duration (in ms)\n",
    "        loop=0  # Infinite loop\n",
    "    )\n",
    "    print(f\"Gameplay saved as {filename}\")\n",
    "\n",
    "\n",
    "def test_model_and_save_video_as_left_agent(model_path, env_name, timesteps=2500, gif_filename=\"gameplay_as_left_agent.gif\"):\n",
    "    \"\"\"\n",
    "    Test a trained model for the left paddle on Pong and save gameplay as a GIF\n",
    "    from the perspective of the left agent.\n",
    "    \"\"\"\n",
    "    # Load the trained model\n",
    "    model = PPO.load(model_path)\n",
    "\n",
    "    # Create the test environment\n",
    "    env = create_test_env(env_name)\n",
    "    obs = env.reset()\n",
    "\n",
    "    frames = []\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in range(timesteps):\n",
    "        # Get action from the model\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, dones, infos = env.step(action)\n",
    "        total_reward += reward.sum()\n",
    "\n",
    "        # Render and store the frame\n",
    "        rendered_frame = env.envs[0].render()\n",
    "        frames.append(rendered_frame)\n",
    "\n",
    "        if dones.any():  # If any environment finishes\n",
    "            print(f\"Episode finished after {t + 1} timesteps.\")\n",
    "            obs = env.reset()  # Reset the environment\n",
    "            break\n",
    "\n",
    "    # Save the video as a GIF with flipping for the left agent perspective\n",
    "    save_video_as_left_agent(frames, filename=gif_filename)\n",
    "\n",
    "    print(f\"Total Reward: {total_reward}\")\n",
    "    env.close()\n",
    "\n",
    "\n",
    "# Test the left-paddle model and save video as a GIF from the left perspective\n",
    "test_model_and_save_video_as_left_agent(\n",
    "    model_path=model_path_left, # Update with the actual path\n",
    "    env_name=\"PongNoFrameskip-v4\",\n",
    "    timesteps=2500,\n",
    "    gif_filename=\"../../videos/pong/left_paddle_gameplay_as_left_agent.gif\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_prova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
